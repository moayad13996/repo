{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#**preparing survey data for looker studio**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m162.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m188.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.3.1 pandas-2.3.1 tzdata-2025.2\n",
      "Successfully loaded 'survey_data_updated 5.csv'. Shape: (18845, 114)\n",
      "Columns available: ['ResponseId', 'MainBranch', 'Age', 'Employment', 'RemoteWork', 'Check', 'CodingActivities', 'EdLevel', 'LearnCode', 'LearnCodeOnline', 'TechDoc', 'YearsCode', 'YearsCodePro', 'DevType', 'OrgSize', 'PurchaseInfluence', 'BuyNewTool', 'BuildvsBuy', 'TechEndorse', 'Country', 'Currency', 'CompTotal', 'LanguageHaveWorkedWith', 'LanguageWantToWorkWith', 'LanguageAdmired', 'DatabaseHaveWorkedWith', 'DatabaseWantToWorkWith', 'DatabaseAdmired', 'PlatformHaveWorkedWith', 'PlatformWantToWorkWith', 'PlatformAdmired', 'WebframeHaveWorkedWith', 'WebframeWantToWorkWith', 'WebframeAdmired', 'EmbeddedHaveWorkedWith', 'EmbeddedWantToWorkWith', 'EmbeddedAdmired', 'MiscTechHaveWorkedWith', 'MiscTechWantToWorkWith', 'MiscTechAdmired', 'ToolsTechHaveWorkedWith', 'ToolsTechWantToWorkWith', 'ToolsTechAdmired', 'NEWCollabToolsHaveWorkedWith', 'NEWCollabToolsWantToWorkWith', 'NEWCollabToolsAdmired', 'OpSysPersonal use', 'OpSysProfessional use', 'OfficeStackAsyncHaveWorkedWith', 'OfficeStackAsyncWantToWorkWith', 'OfficeStackAsyncAdmired', 'OfficeStackSyncHaveWorkedWith', 'OfficeStackSyncWantToWorkWith', 'OfficeStackSyncAdmired', 'AISearchDevHaveWorkedWith', 'AISearchDevWantToWorkWith', 'AISearchDevAdmired', 'NEWSOSites', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOHow', 'SOComm', 'AISelect', 'AISent', 'AIBen', 'AIAcc', 'AIComplex', 'AIToolCurrently Using', 'AIToolInterested in Using', 'AIToolNot interested in Using', 'AINextMuch more integrated', 'AINextNo change', 'AINextMore integrated', 'AINextLess integrated', 'AINextMuch less integrated', 'AIThreat', 'AIEthics', 'AIChallenges', 'TBranch', 'ICorPM', 'WorkExp', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'Frequency_1', 'Frequency_2', 'Frequency_3', 'TimeSearching', 'TimeAnswering', 'Frustration', 'ProfessionalTech', 'ProfessionalCloud', 'ProfessionalQuestion', 'Industry', 'JobSatPoints_1', 'JobSatPoints_4', 'JobSatPoints_5', 'JobSatPoints_6', 'JobSatPoints_7', 'JobSatPoints_8', 'JobSatPoints_9', 'JobSatPoints_10', 'JobSatPoints_11', 'SurveyLength', 'SurveyEase', 'ConvertedCompYearly', 'JobSat']\n",
      "\n",
      "--- Processing Multi-Select Columns ---\n",
      "\n",
      "Processing column: 'LanguageHaveWorkedWith'...\n",
      "Successfully created 'top_languages_used.csv' with top 10 items for 'LanguageHaveWorkedWith'.\n",
      "\n",
      "Processing column: 'DatabaseHaveWorkedWith'...\n",
      "Successfully created 'top_databases_used.csv' with top 10 items for 'DatabaseHaveWorkedWith'.\n",
      "\n",
      "Processing column: 'PlatformHaveWorkedWith'...\n",
      "Successfully created 'top_platforms_used.csv' with top 10 items for 'PlatformHaveWorkedWith'.\n",
      "\n",
      "Processing column: 'WebframeHaveWorkedWith'...\n",
      "Successfully created 'top_web_frameworks_used.csv' with top 10 items for 'WebframeHaveWorkedWith'.\n",
      "\n",
      "Processing column: 'LanguageWantToWorkWith'...\n",
      "Successfully created 'top_languages_desired.csv' with top 10 items for 'LanguageWantToWorkWith'.\n",
      "\n",
      "Processing column: 'DatabaseWantToWorkWith'...\n",
      "Successfully created 'top_databases_desired.csv' with top 10 items for 'DatabaseWantToWorkWith'.\n",
      "\n",
      "Processing column: 'PlatformWantToWorkWith'...\n",
      "Successfully created 'top_platforms_desired.csv' with top 10 items for 'PlatformWantToWorkWith'.\n",
      "\n",
      "Processing column: 'WebframeWantToWorkWith'...\n",
      "Successfully created 'top_web_frameworks_desired.csv' with top 10 items for 'WebframeWantToWorkWith'.\n",
      "\n",
      "--- Preparing Demographics Data ---\n",
      "Created 'Age_Grouped' column. Unique values (first 10): ['35-44', '45-54', '25-34', '55-64', '18-24', 'Under 18', '65+', 'Prefer not to say']\n",
      "\n",
      "Successfully created 'survey_demographics_cleaned.csv' for demographics dashboards. Shape: (18845, 5)\n",
      "   ResponseId Age_Grouped                                            Country  \\\n",
      "0           2       35-44  United Kingdom of Great Britain and Northern I...   \n",
      "1           3       45-54  United Kingdom of Great Britain and Northern I...   \n",
      "2          10       35-44                                             Serbia   \n",
      "3          11       35-44                           United States of America   \n",
      "4          12       45-54                                             Poland   \n",
      "\n",
      "                                           EdLevel  \\\n",
      "0     Bachelor's degree (B.A., B.S., B.Eng., etc.)   \n",
      "1  Master's degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "2  Master's degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3     Bachelor's degree (B.A., B.S., B.Eng., etc.)   \n",
      "4   Professional degree (JD, MD, Ph.D, Ed.D, etc.)   \n",
      "\n",
      "                                          Employment  \n",
      "0                                Employed, full-time  \n",
      "1                                Employed, full-time  \n",
      "2  Independent contractor, freelancer, or self-em...  \n",
      "3                                Employed, full-time  \n",
      "4                                Employed, full-time  \n",
      "\n",
      "--- All Data Preparation Complete ---\n",
      "Please upload the following CSV files to Google Looker Studio:\n",
      "- top_languages_used.csv\n",
      "- top_databases_used.csv\n",
      "- top_platforms_used.csv\n",
      "- top_web_frameworks_used.csv\n",
      "- top_languages_desired.csv\n",
      "- top_databases_desired.csv\n",
      "- top_platforms_desired.csv\n",
      "- top_web_frameworks_desired.csv\n",
      "- survey_demographics_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import os\n",
    "import re # For processing age strings\n",
    "\n",
    "# --- Configuration ---\n",
    "original_csv_name = \"survey_data_updated 5.csv\"\n",
    "# List of multi-select columns to process and their desired output file names\n",
    "multi_select_columns_config = {\n",
    "    'LanguageHaveWorkedWith': 'top_languages_used.csv',\n",
    "    'DatabaseHaveWorkedWith': 'top_databases_used.csv', # CORRECTED: Changed 'DatabaseWorkedWith' to 'DatabaseHaveWorkedWith'\n",
    "    'PlatformHaveWorkedWith': 'top_platforms_used.csv',\n",
    "    'WebframeHaveWorkedWith': 'top_web_frameworks_used.csv',\n",
    "    # Corrected \"Desired Next Year\" column names based on your provided df.columns.tolist()\n",
    "    'LanguageWantToWorkWith': 'top_languages_desired.csv',\n",
    "    'DatabaseWantToWorkWith': 'top_databases_desired.csv',\n",
    "    'PlatformWantToWorkWith': 'top_platforms_desired.csv',\n",
    "    'WebframeWantToWorkWith': 'top_web_frameworks_desired.csv',\n",
    "}\n",
    "\n",
    "# Number of top items to select for each category\n",
    "top_n_items = 10\n",
    "\n",
    "# Output file name for the cleaned main demographics data\n",
    "demographics_output_csv = 'survey_demographics_cleaned.csv'\n",
    "\n",
    "# --- Data Loading ---\n",
    "try:\n",
    "    df = pd.read_csv(original_csv_name)\n",
    "    print(f\"Successfully loaded '{original_csv_name}'. Shape: {df.shape}\")\n",
    "    print(f\"Columns available: {df.columns.tolist()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{original_csv_name}' not found. Please ensure the file is in the correct directory.\")\n",
    "    print(\"Attempting to download from a common course data URL as a fallback...\")\n",
    "    try:\n",
    "        # Fallback URL - adjust if your file comes from a different source\n",
    "        common_file_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/HLOosvsPgIwt5dgOOh1RSg/survey-data-updated.csv\"\n",
    "        df = pd.read_csv(common_file_url)\n",
    "        df.to_csv(original_csv_name, index=False) # Save it locally for future runs\n",
    "        print(f\"Successfully downloaded and loaded '{original_csv_name}' from URL.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download from URL: {e}. Please ensure the file is accessible or manually place it.\")\n",
    "        exit() # Exit if unable to load data\n",
    "\n",
    "\n",
    "# --- Helper Function to Process Multi-Select Columns ---\n",
    "def process_multi_select_column(dataframe, column_name, output_csv_name, n=10):\n",
    "    \"\"\"\n",
    "    Processes a multi-select column by splitting, stacking, counting frequencies,\n",
    "    and saving the top N items to a new CSV file.\n",
    "    Includes a 'Rank' column for Looker Studio.\n",
    "    \"\"\"\n",
    "    if column_name not in dataframe.columns:\n",
    "        print(f\"WARNING: Column '{column_name}' not found in the DataFrame. Skipping processing.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nProcessing column: '{column_name}'...\")\n",
    "\n",
    "    # Handle Missing Values: Drop rows with NaN values in the specified column.\n",
    "    cleaned_series = dataframe[column_name].dropna()\n",
    "\n",
    "    if cleaned_series.empty:\n",
    "        print(f\"No non-null data in '{column_name}'. Skipping CSV creation for this column.\")\n",
    "        return\n",
    "\n",
    "    # Split and Stack: Split the string by ';' delimiter and stack them.\n",
    "    all_individual_items = cleaned_series.str.split(';', expand=True).stack()\n",
    "\n",
    "    # Count Frequencies: Use value_counts() to get the popularity of each technology.\n",
    "    item_counts = all_individual_items.value_counts()\n",
    "\n",
    "    # Select Top N: Get the top N most frequent technologies.\n",
    "    top_n_items_series = item_counts.nlargest(n)\n",
    "\n",
    "    if top_n_items_series.empty:\n",
    "        print(f\"No top {n} items found in '{column_name}' after processing. Skipping CSV creation.\")\n",
    "        return\n",
    "\n",
    "    # Convert to DataFrame for saving\n",
    "    output_df = top_n_items_series.reset_index()\n",
    "    output_df.columns = ['Item', 'Count'] # Rename columns for clarity\n",
    "\n",
    "    # Add a 'Rank' column based on 'Count'\n",
    "    output_df['Rank'] = output_df['Count'].rank(method='min', ascending=False).astype(int)\n",
    "    output_df = output_df.sort_values(by='Rank') # Sort by rank for consistency\n",
    "\n",
    "    # Save to CSV\n",
    "    output_df.to_csv(output_csv_name, index=False)\n",
    "    print(f\"Successfully created '{output_csv_name}' with top {n} items for '{column_name}'.\")\n",
    "    # print(output_df.head()) # Uncomment to see head of each generated CSV\n",
    "\n",
    "# --- Helper Function to Parse Age Strings to Consistent Categories ---\n",
    "def parse_age_string_for_demographics(age_str):\n",
    "    \"\"\"\n",
    "    Parses age strings (e.g., '25-34 years old') into a consistent categorical format (e.g., '25-34').\n",
    "    Handles 'Under 18', '65 or older', and 'Prefer not to say'.\n",
    "    \"\"\"\n",
    "    if pd.isna(age_str):\n",
    "        return None\n",
    "    age_str = str(age_str).strip().lower()\n",
    "\n",
    "    if 'under 18' in age_str:\n",
    "        return 'Under 18'\n",
    "    elif '18-24' in age_str:\n",
    "        return '18-24'\n",
    "    elif '25-34' in age_str:\n",
    "        return '25-34'\n",
    "    elif '35-44' in age_str:\n",
    "        return '35-44'\n",
    "    elif '45-54' in age_str:\n",
    "        return '45-54'\n",
    "    elif '55-64' in age_str:\n",
    "        return '55-64'\n",
    "    elif '65 years or older' in age_str:\n",
    "        return '65+'\n",
    "    elif 'prefer not to say' in age_str:\n",
    "        return 'Prefer not to say'\n",
    "    else:\n",
    "        # Fallback for any other unexpected formats, return as is or None\n",
    "        return age_str # Looker Studio can handle these as distinct categories\n",
    "\n",
    "\n",
    "# --- Main Data Processing for Dashboards ---\n",
    "\n",
    "# 1. Process all multi-select columns\n",
    "print(\"\\n--- Processing Multi-Select Columns ---\")\n",
    "for col_name, output_file in multi_select_columns_config.items():\n",
    "    process_multi_select_column(df, col_name, output_file, n=top_n_items)\n",
    "\n",
    "# 2. Prepare main demographics data (including processed Age)\n",
    "print(\"\\n--- Preparing Demographics Data ---\")\n",
    "if 'Age' in df.columns:\n",
    "    df['Age_Grouped'] = df['Age'].apply(parse_age_string_for_demographics)\n",
    "    print(f\"Created 'Age_Grouped' column. Unique values (first 10): {df['Age_Grouped'].dropna().unique().tolist()[:10]}\")\n",
    "else:\n",
    "    print(\"WARNING: 'Age' column not found in original DataFrame. Age-related demographics may be affected.\")\n",
    "\n",
    "# Select relevant columns for the demographics dashboard.\n",
    "# Ensure these columns exist in your original CSV.\n",
    "demographics_columns = [\n",
    "    'ResponseId', # Keep ResponseId for counting distinct users if needed\n",
    "    'Age_Grouped', # The new processed age column\n",
    "    'Country',\n",
    "    'EdLevel',\n",
    "    'Employment'\n",
    "]\n",
    "\n",
    "# Filter out only the columns we need for demographics and drop rows with NaNs in critical demographic columns\n",
    "# Adjust `subset` as per which columns are absolutely critical for all demographic panels\n",
    "df_demographics_cleaned = df[demographics_columns].dropna(subset=['Age_Grouped', 'Country', 'EdLevel', 'Employment'])\n",
    "\n",
    "# Save the cleaned demographics DataFrame to a new CSV\n",
    "df_demographics_cleaned.to_csv(demographics_output_csv, index=False)\n",
    "print(f\"\\nSuccessfully created '{demographics_output_csv}' for demographics dashboards. Shape: {df_demographics_cleaned.shape}\")\n",
    "print(df_demographics_cleaned.head())\n",
    "\n",
    "\n",
    "print(\"\\n--- All Data Preparation Complete ---\")\n",
    "print(\"Please upload the following CSV files to Google Looker Studio:\")\n",
    "for output_file in multi_select_columns_config.values():\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"- {output_file}\")\n",
    "    else:\n",
    "        print(f\"- {output_file} (Not created, check warnings above)\")\n",
    "if os.path.exists(demographics_output_csv):\n",
    "    print(f\"- {demographics_output_csv}\")\n",
    "else:\n",
    "    print(f\"- {demographics_output_csv} (Not created, check warnings above)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "fe9a23bbf02aada34ca743dbe8962f1c0a4523e59fbfc3db3fccc00328122c6e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
